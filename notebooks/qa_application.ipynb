{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook sets up a question answering system using LangChain, Google Generative AI embeddings, and a Chroma vector database. Here's a breakdown:\n",
    "\n",
    "1. **Data Preparation:**\n",
    "    - Loads Python code files from a directory.\n",
    "    - Splits these code files into smaller, more manageable chunks.\n",
    "    - Embeds these chunks using Google's embedding model.\n",
    "\n",
    "2. **Vector Database:**\n",
    "    - Checks if a local Chroma database exists. \n",
    "    - If not, creates one and stores the embedded code chunks.\n",
    "    - If it exists, loads the database from disk.\n",
    "\n",
    "3. **Retrieval System Setup:**\n",
    "    - Configures a retriever to search for relevant code chunks in the database using the MMR (Maximal Marginal Relevance) method.\n",
    "\n",
    "4. **Language Model Configuration:**\n",
    "    - Initializes Google's `gemini-1.5-flash` language model for generating responses.\n",
    "    - Defines safety settings to control potentially harmful content in the model's output.\n",
    "\n",
    "5. **Question Answering Chain:**\n",
    "    - Constructs a multi-step chain:\n",
    "        - Takes user questions and the conversation history as input.\n",
    "        - Generates relevant search queries using the language model.\n",
    "        - Retrieves relevant code chunks from the database.\n",
    "        - Uses the retrieved context and language model to formulate an answer.\n",
    "\n",
    "6. **Testing:**\n",
    "    - Tests the question-answering system with sample questions about Python code concepts.\n",
    "    - Prints both the questions and the generated answers.\n",
    "\n",
    "In essence, this notebook sets up a system that can answer questions about a codebase by intelligently searching for and understanding relevant code snippets, providing a powerful tool for code exploration and assistance. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os  # Used for interacting with the operating system\n",
    "from dotenv import load_dotenv  # Used to load environment variables from a .env file\n",
    "\n",
    "load_dotenv()  # Load environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rafael/.pyenv/versions/3.10.14/envs/qa-with-rag/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import LangChain libraries\n",
    "from langchain_community.document_loaders.generic import GenericLoader\n",
    "from langchain_community.document_loaders.parsers import LanguageParser\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain_text_splitters import Language\n",
    "from langchain.chains import create_history_aware_retriever, create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from google.generativeai.types.safety_types import (\n",
    "    HarmBlockThreshold,\n",
    "    HarmCategory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory to persist the database\n",
    "PERSIST_DIRECTORY = \"/home/rafael/Downloads/qa-with-rag/src/data/\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://github.com/langchain-ai/langchain/archive/refs/heads/master.zip\n",
    "# !unzip /home/rafael/Downloads/qa-with-rag/notebooks/master.zip\n",
    "# !rm -rf /home/rafael/Downloads/qa-with-rag/notebooks/langchain-master/.github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "413"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Document Loading and Processing ---\n",
    "# Load documents from the filesystem\n",
    "loader = GenericLoader.from_filesystem(\n",
    "    \"/home/rafael/Downloads/qa-with-rag/notebooks/langchain-master/libs/core/langchain_core\",  # Path to the files\n",
    "    glob=\"**/*\",  # Load all files within the directory\n",
    "    suffixes=[\".py\"],  # Load only Python files\n",
    "    exclude=[\"**/non-utf8-encoding.py\"],  # Exclude this specific file\n",
    "    parser=LanguageParser(language=Language.PYTHON, parser_threshold=500),  # Use a parser for Python files with a threshold of 500 tokens\n",
    ")\n",
    "documents = loader.load()  # Load the documents\n",
    "len(documents)  # Print the number of documents loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1288"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Split Documents into Smaller Chunks ---\n",
    "# Initialize the text splitter for Python code\n",
    "python_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.PYTHON, chunk_size=2000, chunk_overlap=200\n",
    ")\n",
    "texts = python_splitter.split_documents(documents)  # Split the documents into smaller texts\n",
    "len(texts)  # Print the number of texts after splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing database from /home/rafael/Downloads/qa-with-rag/src/data/...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1721576089.253500  469752 config.cc:230] gRPC experiments enabled: call_status_override_on_cancellation, event_engine_dns, event_engine_listener, http2_stats_fix, monitoring_experiment, pick_first_new, trace_record_callops, work_serializer_clears_time_cache\n",
      "I0000 00:00:1721576089.263872  469752 check_gcp_environment.cc:61] BIOS data file does not exist or cannot be opened.\n"
     ]
    }
   ],
   "source": [
    "# --- Create or Load the Vector Database ---\n",
    "# Initialize the Google embeddings model\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "\n",
    "# Check if the database already exists\n",
    "if not os.path.exists(PERSIST_DIRECTORY):\n",
    "    print(f\"Creating database in {PERSIST_DIRECTORY}...\")\n",
    "    # Create the Chroma database and persist the documents\n",
    "    db = Chroma.from_documents(\n",
    "        documents=texts,\n",
    "        embedding=embeddings,\n",
    "        persist_directory=PERSIST_DIRECTORY\n",
    "    )\n",
    "    db.persist()  # Save the database to disk\n",
    "else:\n",
    "    print(f\"Loading existing database from {PERSIST_DIRECTORY}...\")\n",
    "    # Load the existing database from disk\n",
    "    db = Chroma(persist_directory=PERSIST_DIRECTORY, embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Retrieval Chain Configuration ---\n",
    "# Define the retriever to search for relevant documents in the database\n",
    "retriever = db.as_retriever(\n",
    "    search_type=\"mmr\",  # Use the MMR (Maximal Marginal Relevance) search method\n",
    "    search_kwargs={\"k\": 8},  # Return the 8 most relevant documents\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Language Model (LLM) Configuration ---\n",
    "# Initialize the ChatGoogleGenerativeAI language model\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash\",  # Specify the 'gemini-1.5-flash' language model\n",
    "    temperature=0,  # Set the temperature to 0 (more deterministic responses)\n",
    "    top_k=10,  # Consider the top 10 most likely tokens during text generation\n",
    "    safety_settings={  # Define the safety settings for the model\n",
    "        HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "        HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "        HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "        HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Question Answering Chain Creation ---\n",
    "# Define a prompt to generate search queries based on the conversation history\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"placeholder\", \"{chat_history}\"),  # Use the conversation history as context\n",
    "        (\"user\", \"{input}\"),  # User input\n",
    "        (\n",
    "            \"user\",\n",
    "            \"Given the above conversation, generate a search query to look up to get information relevant to the conversation\",\n",
    "        ),  # Instruction to generate the search query\n",
    "    ]\n",
    ")\n",
    "# Create a history-aware retriever chain\n",
    "retriever_chain = create_history_aware_retriever(llm, retriever, prompt)\n",
    "\n",
    "# Define a prompt to provide context to the language model\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Answer the user's questions based on the below context:\\n\\n{context}\",\n",
    "        ),  # Instruction for the model to use the provided context\n",
    "        (\"placeholder\", \"{chat_history}\"),  # Use the conversation history as additional context\n",
    "        (\"user\", \"{input}\"),  # User input\n",
    "    ]\n",
    ")\n",
    "# Create a document chain to format retrieved documents\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "\n",
    "# Create the question answering chain by combining the retriever chain and document chain\n",
    "qa = create_retrieval_chain(retriever_chain, document_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Question Answering Chain Testing ---\n",
    "# Define a test question\n",
    "question = \"What is a RunnableBinding?\"\n",
    "# Run the question answering chain with the question\n",
    "result = qa.invoke({\"input\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> **Question**: What classes are derived from the Runnable class? \n",
      "\n",
      "**Answer**: The provided code snippet doesn't explicitly list all classes derived from `Runnable`, but it does show several classes that inherit from it either directly or indirectly:\n",
      "\n",
      "**Directly Inheriting from Runnable:**\n",
      "\n",
      "* **RunnableSequence:** This class represents a sequence of Runnables.\n",
      "* **RunnableParallel:** This class represents a parallel execution of Runnables.\n",
      "* **RunnableGenerator:** This class represents a Runnable that generates a sequence of outputs.\n",
      "* **RunnableLambda:** This class represents a Runnable that wraps a lambda function.\n",
      "\n",
      "**Indirectly Inheriting from Runnable:**\n",
      "\n",
      "* **RunnableEach:** This class inherits from `RunnableEachBase`, which in turn inherits from `RunnableSerializable`, which inherits from `Runnable`.\n",
      "* **RunnableBinding:** This class inherits from `RunnableBindingBase`, which in turn inherits from `RunnableSerializable`, which inherits from `Runnable`.\n",
      "\n",
      "**Other Relevant Classes:**\n",
      "\n",
      "* **RunnableSerializable:** This class is a base class for Runnables that can be serialized.\n",
      "* **RunnableEachBase:** This class is a base class for Runnables that delegate calls to another Runnable with each element of the input sequence.\n",
      "* **RunnableBindingBase:** This class is a base class for Runnables that delegate calls to another Runnable with a set of kwargs.\n",
      "\n",
      "The code also defines a type alias `RunnableLike` which represents a union of various types that can be coerced into a `Runnable`. This includes:\n",
      "\n",
      "* `Runnable[Input, Output]`\n",
      "* `Callable[[Input], Output]`\n",
      "* `Callable[[Input], Awaitable[Output]]`\n",
      "* `Callable[[Iterator[Input]], Iterator[Output]]`\n",
      "* `Callable[[AsyncIterator[Input]], AsyncIterator[Output]]`\n",
      "* `Mapping[str, Any]`\n",
      "\n",
      "This indicates that various types of objects can be used as Runnables, including functions, coroutines, and mappings.\n",
      " \n",
      "\n",
      "-> **Question**: What one improvement do you propose in code in relation to the class hierarchy for the Runnable class? \n",
      "\n",
      "**Answer**: The provided code snippet showcases a robust and well-structured class hierarchy for the `Runnable` class. However, one potential improvement could be to introduce a more explicit distinction between **synchronous** and **asynchronous** runnables. \n",
      "\n",
      "Currently, the `Runnable` class itself doesn't explicitly differentiate between synchronous and asynchronous execution. This can lead to potential confusion and might require developers to manually check the implementation of a specific `Runnable` subclass to determine its execution mode.\n",
      "\n",
      "**Proposed Improvement:**\n",
      "\n",
      "Introduce two abstract base classes:\n",
      "\n",
      "1. **`SynchronousRunnable`:** This class would represent runnables that execute synchronously.\n",
      "2. **`AsynchronousRunnable`:** This class would represent runnables that execute asynchronously.\n",
      "\n",
      "All existing `Runnable` subclasses would then inherit from either `SynchronousRunnable` or `AsynchronousRunnable` based on their execution behavior. This explicit distinction would improve code clarity and make it easier for developers to understand the execution mode of a given `Runnable` instance.\n",
      "\n",
      "**Example:**\n",
      "\n",
      "```python\n",
      "from abc import ABC, abstractmethod\n",
      "from typing import Any, Awaitable, Callable, Generic, Input, Output, TypeVar\n",
      "\n",
      "class SynchronousRunnable(Runnable[Input, Output], ABC):\n",
      "    @abstractmethod\n",
      "    def invoke(self, input: Input) -> Output:\n",
      "        ...\n",
      "\n",
      "class AsynchronousRunnable(Runnable[Input, Output], ABC):\n",
      "    @abstractmethod\n",
      "    async def invoke(self, input: Input) -> Output:\n",
      "        ...\n",
      "\n",
      "# Example subclass inheriting from SynchronousRunnable\n",
      "class MySynchronousRunnable(SynchronousRunnable[str, str]):\n",
      "    def invoke(self, input: str) -> str:\n",
      "        return input.upper()\n",
      "\n",
      "# Example subclass inheriting from AsynchronousRunnable\n",
      "class MyAsynchronousRunnable(AsynchronousRunnable[str, str]):\n",
      "    async def invoke(self, input: str) -> str:\n",
      "        await asyncio.sleep(1)\n",
      "        return input.lower()\n",
      "```\n",
      "\n",
      "This change would make the code more readable and maintainable, as it clearly distinguishes between synchronous and asynchronous runnables, reducing the potential for confusion and errors.\n",
      " \n",
      "\n",
      "The provided code snippet showcases a robust and well-structured class hierarchy for the `Runnable` class. However, one potential improvement could be to introduce a more explicit distinction between **synchronous** and **asynchronous** runnables. \n",
      "\n",
      "Currently, the `Runnable` class itself doesn't explicitly differentiate between synchronous and asynchronous execution. This can lead to potential confusion and might require developers to manually check the implementation of a specific `Runnable` subclass to determine its execution mode.\n",
      "\n",
      "**Proposed Improvement:**\n",
      "\n",
      "Introduce two abstract base classes:\n",
      "\n",
      "1. **`SynchronousRunnable`:** This class would represent runnables that execute synchronously.\n",
      "2. **`AsynchronousRunnable`:** This class would represent runnables that execute asynchronously.\n",
      "\n",
      "All existing `Runnable` subclasses would then inherit from either `SynchronousRunnable` or `AsynchronousRunnable` based on their execution behavior. This explicit distinction would improve code clarity and make it easier for developers to understand the execution mode of a given `Runnable` instance.\n",
      "\n",
      "**Example:**\n",
      "\n",
      "```python\n",
      "from abc import ABC, abstractmethod\n",
      "from typing import Any, Awaitable, Callable, Generic, Input, Output, TypeVar\n",
      "\n",
      "class SynchronousRunnable(Runnable[Input, Output], ABC):\n",
      "    @abstractmethod\n",
      "    def invoke(self, input: Input) -> Output:\n",
      "        ...\n",
      "\n",
      "class AsynchronousRunnable(Runnable[Input, Output], ABC):\n",
      "    @abstractmethod\n",
      "    async def invoke(self, input: Input) -> Output:\n",
      "        ...\n",
      "\n",
      "# Example subclass inheriting from SynchronousRunnable\n",
      "class MySynchronousRunnable(SynchronousRunnable[str, str]):\n",
      "    def invoke(self, input: str) -> str:\n",
      "        return input.upper()\n",
      "\n",
      "# Example subclass inheriting from AsynchronousRunnable\n",
      "class MyAsynchronousRunnable(AsynchronousRunnable[str, str]):\n",
      "    async def invoke(self, input: str) -> str:\n",
      "        await asyncio.sleep(1)\n",
      "        return input.lower()\n",
      "```\n",
      "\n",
      "This change would make the code more readable and maintainable, as it clearly distinguishes between synchronous and asynchronous runnables, reducing the potential for confusion and errors.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define a list of questions to test\n",
    "questions = [\n",
    "    \"What classes are derived from the Runnable class?\",\n",
    "    \"What one improvement do you propose in code in relation to the class hierarchy for the Runnable class?\",\n",
    "]\n",
    "# Iterate over the list of questions, run the question answering chain, and print the results\n",
    "for question in questions:\n",
    "    result = qa.invoke({\"input\": question})\n",
    "    print(f\"-> **Question**: {question} \\n\")\n",
    "    print(f\"**Answer**: {result['answer']} \\n\")\n",
    "print(result[\"answer\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qa-with-rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
